{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순한 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.619379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.857290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.628194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.725426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.498926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.867042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.934539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.864829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.241539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.823689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     x         y\n",
       "0           0   1.0  1.619379\n",
       "1           1   2.0  1.857290\n",
       "2           2   3.0  2.628194\n",
       "3           3   4.0  2.725426\n",
       "4           4   5.0  3.498926\n",
       "5           5   6.0  3.867042\n",
       "6           6   7.0  4.934539\n",
       "7           7   8.0  4.864829\n",
       "8           8   9.0  5.241539\n",
       "9           9  10.0  5.823689"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./Data/Linear_Regression_model_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 9.],\n",
       "        [10.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6194],\n",
       "        [1.8573],\n",
       "        [2.6282],\n",
       "        [2.7254],\n",
       "        [3.4989],\n",
       "        [3.8670],\n",
       "        [4.9345],\n",
       "        [4.8648],\n",
       "        [5.2415],\n",
       "        [5.8237]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x24849bff048>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlim(0, 11); plt.ylim(0, 8)\n",
    "plt.title('Linear_Regression_Model_Data')\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST datasets Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Normalize data with mean=0.5, std=1.0\n",
    "mnist_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision.transforms\n",
    "이미지 변환 함수를 포함\n",
    "* transforms.CenterCrop(size): 이미지 중앙 부분 크롭하여 [size, size] 로 변환\n",
    "* transforms.Resize(size, interpolation=2): 이미지를 지정한 크기로 변환\n",
    "* transforms.RandomCrop(size, padding=None, pad_if_needed=False, fill=0, padding_mode='constant'): 이미지의 랜덤부분을 [size, size] 만큼 crop. input이 size 보다 작으면 설정한 padding을 추가\n",
    "* transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.74, 3/4), interpolation=2): 이미지를 랜덤한 크기 및 비율로 crop\n",
    "* transforms.RandomRotation(degrees, resample=False, expand=False, center=None): 이미지를 랜덤한 각도로 회전   \n",
    "\n",
    "더 많은 정보는 [torchvision.transforms](https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=torchvision%20transforms) 에서 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 모든 transforms 변환 함수를 조합하여 dataloader 에 넘겨줄 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    CenterCrop(size=(14, 14))\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.Compose([transforms.CenterCrop(14), transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "download_root = './Data'\n",
    "\n",
    "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
    "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./Data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(1.0,))\n",
       "           )"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST datasets 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64  # batch size 를 64 로 설정\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "first_data = train_dataloader.__iter__().__next__()\n",
    "print(first_data[0].size(), first_data[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
       "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
       "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset 만들기\n",
    "torch.utils.data.Dataset 를 상속하여 만들 수 있음\n",
    "* `__len__(self)`: dataset 전체 개수를 알려준다\n",
    "* `__getitem__(self, idx)`: parameter로 idx를 넘겨주면 dix번째 데이터를 반환한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "simple_datas, simple_labels = first_data[0], first_data[1]\n",
    "class customDataloader(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.x = data\n",
    "        self.y = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx, :, :, :]\n",
    "        y = self.y[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = customDataloader(simple_datas, simple_labels)\n",
    "custom_dataloader = DataLoader(custom_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = custom_dataloader.__iter__().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 28, 28]), torch.Size([2]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size(), b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
